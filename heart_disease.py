# -*- coding: utf-8 -*-
"""Heart Disease

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cHPqb10xv5PXmkdGd94ybot3Hsiy5Jgq
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

data =pd.read_csv("/content/Heart_Disease.csv")

data.info()

data['Gender']=data['Gender'].replace("Male",0)
data['Gender']=data['Gender'].replace("Female",1)
data['Gender'].head(20)

data['Heart Disease']=data['Heart Disease'].replace("No",0)
data['Heart Disease']=data['Heart Disease'].replace("Yes",1)

import missingno as msno
msno.matrix(data)
plt.show()

print(data.isnull().sum())

data['Age'].fillna(data['Age'].mean(),inplace=True)
data['Age'].tail(20)

data['Gender'].fillna(1.0, inplace=True)
data['Gender'].head(20)

data=pd.get_dummies(data,columns=['Chest pain type', 'EKG results', 'Slope of ST', 'Thallium', 'smoking_status','work_type'])

print (data.isnull().sum())

data.duplicated().sum()

sns.boxplot(data=data, palette='rainbow', orient='h')

for col in data.columns:
    # Check if the column has outliers (values outside of 1.5 times the interquartile range)
    q1 = data[col].quantile(0.25)
    q3 = data[col].quantile(0.75)
    IQR = q3 - q1
    lower_limit = q1 - 1.5*IQR
    upper_limit = q3 + 1.5*IQR
    if (data[col] > upper_limit).sum() + (data[col] < lower_limit).sum() > 0:
        # Replace the outliers with the maximum and minimum values of the column
        data[col] = data[col].clip(lower_limit, upper_limit)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
data[['Age', 'BP', 'Cholesterol', 'FBS over 120', 'Max HR', 'ST depression']] = scaler.fit_transform(data[['Age', 'BP', 'Cholesterol', 'FBS over 120', 'Max HR', 'ST depression']])

corr_coeffs = data.corr()['Heart Disease']
fig, ax = plt.subplots(figsize=(100,10))
ax.bar(corr_coeffs.index, corr_coeffs.values)
ax.set_xlabel('Features')
ax.set_ylabel('Correlation Coefficient')
ax.set_title('Correlation between Features and Target Variable')
plt.show()

data=data.drop('id',axis=1)
data=data.drop('work_type_Govt_job',axis=1)
data=data.drop('work_type_Never_worked',axis=1)
data=data.drop('work_type_Private',axis=1)
data=data.drop('work_type_Self-employed',axis=1)
data=data.drop('work_type_children',axis=1)

x=data.drop('Heart Disease',axis=1)
y=data['Heart Disease']
x.head()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, classification_report
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=44)

# Logistic Regression
lr_model = LogisticRegression()
lr_model.fit(x_train, y_train)
lr_pred = lr_model.predict(x_test)
lr_acc = accuracy_score(y_test, lr_pred)
lr_mse = mean_squared_error(y_test, lr_pred)
lr_cm = confusion_matrix(y_test, lr_pred)
lr_cr = classification_report(y_test, lr_pred)
print("\nLogistic Regression model results:")
print("Logistic Regression accuracy:", lr_acc)
print("Mean Squared Error:", lr_mse)
print("Confusion Matrix:\n", lr_cm)
print("Classification Report:\n", lr_cr)

from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,lr_pred)
plt.title('Heatmap of confusion_matrix',fontsize=15)
sns.heatmap(cm,annot=True)
plt.show()

svm_model = SVC()
svm_model.fit(x_train, y_train)
svm_pred = svm_model.predict(x_test)
svm_acc = accuracy_score(y_test, svm_pred)
svm_mse = mean_squared_error(y_test, svm_pred)
svm_cm = confusion_matrix(y_test, svm_pred)
svm_cr = classification_report(y_test, svm_pred)
print("SVM model results:")
print("SVM accuracy:", svm_acc)
print("Mean Squared Error:", svm_mse)
print("Confusion Matrix:\n", svm_cm)
print("Classification Report:\n", svm_cr)

from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,svm_pred)
plt.title('Heatmap of confusion_matrix',fontsize=15)
sns.heatmap(cm,annot=True)
plt.show()

id3_model = DecisionTreeClassifier(random_state=2023)
id3_model.fit(x_train, y_train)
id3_pred = id3_model.predict(x_test)
id3_acc = accuracy_score(y_test, id3_pred)
id3_mse = mean_squared_error(y_test, id3_pred)
id3_cm = confusion_matrix(y_test, id3_pred)
id3_cr = classification_report(y_test, id3_pred)
print("\nID3 model results:")
print("ID3 accuracy:", id3_acc)
print("Mean Squared Error:", id3_mse)
print("Confusion Matrix:\n", id3_cm)
print("Classification Report:\n", id3_cr)

from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,id3_pred)
plt.title('Heatmap of confusion_matrix',fontsize=15)
sns.heatmap(cm,annot=True)
plt.show()

print (lr_acc)
print(svm_acc)
print(id3_acc)

TestData=pd.DataFrame({
    'Age':52,
    'Gender':1,
    'Chest pain type':1,
    'BP':125,
    'Cholesterol':212,
    'FBS over 120':0,
    'EKG results':1,
    'Max HR':120,
    'Exercise angina':0,
    'ST depression':1.0,
    'Slope of ST':2,
    'Number of vessels fluro':0,
    'Thallium':3,
    'smoking_status':0, 
    },index=[0])

TestData=pd.get_dummies(TestData,columns=['smoking_status','Chest pain type','EKG results','Slope of ST','Thallium'])

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
TestData[['Age', 'BP', 'Cholesterol', 'FBS over 120', 'Max HR', 'ST depression']] = scaler.fit_transform(TestData[['Age', 'BP', 'Cholesterol', 'FBS over 120', 'Max HR', 'ST depression']])

missing_col=set(x.columns)-set(TestData.columns)
for col in missing_col:
  TestData[col]=0

TestData = TestData.loc[:, x.columns]

ans=id3_model.predict(TestData)

if ans==0:
  print("You Don't have Heart disease")
else:
  print("You have Heart disease")